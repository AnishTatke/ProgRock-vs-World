{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e178d-dbbf-4a79-9d6b-36e722ec74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "from ProgDataset import SnippetProgDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22518c9-cb59-4ae3-89ca-ffd53c67edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bb521-9b9e-4d59-ae7e-f825198ff620",
   "metadata": {},
   "outputs": [],
   "source": [
    "getName = lambda s : s.split('\\\\')[-1]\n",
    "def splitSongs(split = 0.8, path = \"\"):\n",
    "    prog_folder = \"Progressive_Rock_Songs\" if path == \"\" else os.path.join(path + \"//\" + \"Progressive_Rock_Songs\")\n",
    "    non_prog_folder = \"Not_Progressive_Rock\" if path == \"\" else os.path.join(path + \"//\" + \"Not_Progressive_Rock\")\n",
    "    songs = [(i, getName(i), 1) for i in librosa.util.find_files(prog_folder)] + [(i, getName(i), 0) for i in librosa.util.find_files(non_prog_folder)]\n",
    "\n",
    "    split_idx = int(split * len(songs))\n",
    "    return songs[:split_idx], songs[split_idx:]\n",
    "\n",
    "train_songs, validate_songs = splitSongs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d9082d-83c6-4d9c-91ae-40bf810fc79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = SnippetProgDataset(train_songs, transform = transform)\n",
    "validate_dataset = SnippetProgDataset(validate_songs, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff2616-b7ad-46f8-9647-70e2ae34be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "print(f\"The current device used is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188dadbf-1396-4b7b-a326-25bdfc9c908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671e364-5e39-4b04-827f-18dd6ad52e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "validation_loader = DataLoader(validate_dataset, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74faf1f-2096-4d97-b9d6-ff78ecfe336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProgCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "        # self.conv3 = nn.Sequential(\n",
    "        #     nn.Conv2d(64, 128, kernel_size = 3),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(kernel_size = 2)\n",
    "        # )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * 38 * 52, 1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(64, 4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(4, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef34b1-9c45-4a43-b3cd-6131d5b86223",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProgCNN()\n",
    "print(summary(model, (1, 160, 216)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0745b48a-5872-45ba-ad0f-42646b2b6df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b6ce4-0bb7-4610-829c-4ff2bf2a1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, train_losses, num_batch_prints = 5):\n",
    "    model.train(True)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_print_idx = len(train_loader) // num_batch_prints\n",
    "    if epoch == 1:\n",
    "        print(f\"Train Epoch: {epoch}\")\n",
    "        \n",
    "    for batch_idx, (inputs, labels, metadata) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs, labels = inputs.float(), labels.float()\n",
    "        \n",
    "        outputs = model(inputs).reshape(-1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        predictions = (outputs > 0.5).long().reshape(-1)\n",
    "        correct += (predictions == labels).sum()\n",
    "        total += len(inputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % batch_print_idx == 0:\n",
    "            print(f\"\\tTrain Batch: {(batch_idx // batch_print_idx) + 1} \\tBatchwise Loss: {loss.item():.4f}\")\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "    print(f\"Train Epoch: {epoch}\\tEpochwise Loss: {loss.item():.4f}\\tEpoch Accuracy: [{correct}/{len(train_loader.dataset)}] {(100. * correct / len(train_loader.dataset)):2f}%\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4ffa8-4093-49e6-b3da-beeef14ad830",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSongPredictions = lambda arr: 1 if sum(arr) > len(arr) / 2 else 0\n",
    "def validate(validation_loader, test_losses):\n",
    "    model.train(False)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, metadata in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs, labels = inputs.float(), labels.float()\n",
    "            \n",
    "            outputs = model(inputs).reshape(-1)\n",
    "            test_loss += loss_fn(outputs, labels).item()\n",
    "            \n",
    "            predictions = (outputs > 0.5).long().reshape(-1)\n",
    "            # print(predictions, metadata['song_idx'], metadata['snippet_idx'])\n",
    "            for idx, song_name in enumerate(metadata['song_name']):\n",
    "                if song_name not in predictions_dict:\n",
    "                    predictions_dict[song_name] = []\n",
    "                predictions_dict[song_name].append(predictions[idx].item())\n",
    "            correct += (predictions == labels).sum()\n",
    "            \n",
    "        test_loss /= len(validation_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f\"Test Set: Avg Loss: {test_loss:.4f}, Accuracy: {correct}/{len(validation_loader.dataset)} ({(100. * correct / len(validation_loader.dataset)):.2f}%)\\n\")\n",
    "        for key in predictions_dict:\n",
    "            predictions_dict[key] = getSongPredictions(predictions_dict[key])\n",
    "        return predictions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe64fa9-65bf-484c-8969-289d7c89818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateSongs(validate_songs, prediction_dict):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for song in validate_songs:\n",
    "        songs_path, song_name, truth = song\n",
    "        if song_name in prediction_dict:\n",
    "            correct += (truth and prediction_dict[song_name]) or (not truth and not prediction_dict[song_name])\n",
    "        total += 1\n",
    "    print(f\"Songs correctly classified {correct}/{total}: {(correct/total * 100):4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b793e5-051e-43da-9e5e-487905b8f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_arr = []\n",
    "test_loss_arr = []\n",
    "correct = 0\n",
    "validateSongs(validate_songs, validate(validation_loader, test_loss_arr))\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    correct += train(epoch, train_loader, train_loss_arr)\n",
    "validateSongs(validate_songs, validate(validation_loader, test_loss_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b9561-72bf-444b-86b8-80ef1fa48c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Environment",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
